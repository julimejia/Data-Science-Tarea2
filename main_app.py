# =============================================================================
# ðŸ“Š DASHBOARD STREAMLIT â€“ CALIDAD DE DATOS & RIESGO OPERATIVO
# =============================================================================
#
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚                             VISIÃ“N GENERAL                                 â”‚
# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
# â”‚                                                                          â”‚
# â”‚  ðŸŸ¦ FASE 1 â€“ INGESTA, LIMPIEZA Y HEALTHCHECK                               â”‚
# â”‚  â€¢ Carga controlada de archivos CSV                                      â”‚
# â”‚  â€¢ Limpieza explÃ­cita de filas invÃ¡lidas                                  â”‚
# â”‚  â€¢ ValidaciÃ³n estructural (columnas requeridas)                           â”‚
# â”‚  â€¢ MÃ©tricas de calidad de datos                                           â”‚
# â”‚  â€¢ CÃ¡lculo de Health Score como gate de anÃ¡lisis                          â”‚
# â”‚                                                                          â”‚
# â”‚  ðŸŸ¦ FASE 2 â€“ SKU FANTASMA (RIESGO OPERATIVO)                                â”‚
# â”‚  â€¢ DetecciÃ³n de transacciones sin respaldo en inventario                  â”‚
# â”‚  â€¢ CuantificaciÃ³n del impacto financiero                                  â”‚
# â”‚  â€¢ Storytelling ejecutivo para toma de decisiones                         â”‚
# â”‚                                                                          â”‚
# â”‚  ðŸŸ¦ PRINCIPIO CLAVE                                                         â”‚
# â”‚  NingÃºn anÃ¡lisis de negocio es confiable                                  â”‚
# â”‚  si los datos no superan un control de calidad previo.                   â”‚
# â”‚                                                                          â”‚
# â”‚  ðŸŸ¦ RESULTADO                                                              â”‚
# â”‚  â€¢ Transparencia en la calidad del dato                                   â”‚
# â”‚  â€¢ Riesgo operativo cuantificado                                          â”‚
# â”‚  â€¢ Evidencia clara de fallas de gobernanza                                 â”‚
# â”‚                                                                          â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
# =============================================================================

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
import io

# =============================================================================
# CONFIGURACIÃ“N DE LA PÃGINA
# =============================================================================
st.set_page_config(
    page_title="Dashboard de AnÃ¡lisis de Datos",
    page_icon="ðŸ“Š",
    layout="wide"
)

st.title("ðŸ“Š Dashboard de AnÃ¡lisis - Datos Empresariales")
st.markdown("---")

# =============================================================================
# SIDEBAR â€“ CARGA DE ARCHIVOS
# =============================================================================
with st.sidebar:
    st.header("ðŸ“¤ Carga de Archivos CSV")

    feedback_file = st.file_uploader(
        "Feedback Clientes (feedback_clientes_v2.csv)",
        type=["csv"]
    )

    inventario_file = st.file_uploader(
        "Inventario Central (inventario_central_v2.csv)",
        type=["csv"]
    )

    transacciones_file = st.file_uploader(
        "Transacciones LogÃ­sticas (transacciones_logisticas_v2.csv)",
        type=["csv"]
    )

    mostrar_limpieza = st.checkbox("Mostrar proceso de limpieza", value=True)

# =============================================================================
# ========================= FASE 1 â€“ INGESTA Y LIMPIEZA =========================
# =============================================================================

def cargar_feedback(file):
    df = pd.read_csv(file)
    df_limpio = df[(df["Edad_Cliente"] >= 0) & (df["Edad_Cliente"] <= 110)].copy()
    return df, df_limpio, len(df) - len(df_limpio)

def cargar_inventario(file):
    df = pd.read_csv(file)
    df_limpio = df.copy()
    filas_eliminadas = 0

    if 500 in df_limpio.index:
        df_limpio = df_limpio.drop(index=500)
        filas_eliminadas += 1

    mask = df_limpio["Stock_Actual"] < 0
    filas_eliminadas += mask.sum()
    df_limpio = df_limpio[~mask]

    return df, df_limpio, filas_eliminadas

def cargar_transacciones(file):
    df = pd.read_csv(file)
    for col in df.columns:
        if "fecha" in col.lower():
            df[col] = pd.to_datetime(df[col], errors="coerce")
    return df, df.copy(), 0

# =============================================================================
# HEALTHCHECK â€“ CONTROL DE CALIDAD DE DATOS
# =============================================================================
def run_healthcheck(df_raw, required_cols=None):
    missing_pct = (df_raw.isna().mean() * 100).round(2)
    duplicates = df_raw.duplicated().sum()

    missing_required = []
    if required_cols:
        missing_required = list(set(required_cols) - set(df_raw.columns))

    score = 100
    score -= missing_pct.sum() / 10
    score -= duplicates * 0.5
    score = max(0, round(score, 2))

    return {
        "rows": len(df_raw),
        "cols": len(df_raw.columns),
        "duplicates": int(duplicates),
        "missing_pct": missing_pct.to_dict(),
        "missing_required_cols": missing_required,
        "health_score": score,
        "status": "ok" if not missing_required else "invalid"
    }

FILES_CONFIG = {
    "Feedback de Clientes": (feedback_file, cargar_feedback, ["Edad_Cliente", "Rating_Producto", "Satisfaccion_NPS"]),
    "Inventario Central": (inventario_file, cargar_inventario, ["SKU_ID", "Categoria", "Stock_Actual", "Punto_Reorden"]),
    "Transacciones LogÃ­sticas": (transacciones_file, cargar_transacciones, None)
}

datasets = {}
health_status = {}

for name, (file, loader, required_cols) in FILES_CONFIG.items():
    if not file:
        health_status[name] = "missing"
        continue

    df_raw, df_clean, filas_eliminadas = loader(file)
    health = run_healthcheck(df_raw, required_cols)
    health["filas_eliminadas"] = filas_eliminadas

    datasets[name] = {"raw": df_raw, "clean": df_clean, "health": health}
    health_status[name] = health["status"]

# =============================================================================
# VISUALIZACIÃ“N DEL HEALTHCHECK
# =============================================================================
st.subheader("ðŸ“‹ Estado de Calidad de los Datos")

cols = st.columns(3)
for col, (name, status) in zip(cols, health_status.items()):
    with col:
        if status == "ok":
            st.success(f"âœ… {name}")
            hc = datasets[name]["health"]
            with st.expander("Detalles del Healthcheck"):
                st.write(f"Filas: {hc['rows']}")
                st.write(f"Columnas: {hc['cols']}")
                st.write(f"Duplicados: {hc['duplicates']}")
                st.write(f"Filas eliminadas: {hc['filas_eliminadas']}")
                st.metric("Health Score", hc["health_score"])
        elif status == "missing":
            st.warning(f"âš ï¸ {name} no cargado")
        else:
            st.error(f"âŒ {name} invÃ¡lido")

datasets_disponibles = [k for k, v in health_status.items() if v == "ok"]

if not datasets_disponibles:
    st.stop()

# =============================================================================
# ========================= FASE 2 â€“ SKU FANTASMA ===============================
# =============================================================================

if "Inventario Central" in datasets_disponibles and "Transacciones LogÃ­sticas" in datasets_disponibles:

    st.markdown("---")
    st.header("ðŸ‘» FASE 2 â€“ AnÃ¡lisis Avanzado de SKU Fantasma")

    # ============================================================
    # PREPARACIÃ“N DE DATOS
    # ============================================================
    inv = datasets["Inventario Central"]["clean"].copy()
    trx = datasets["Transacciones LogÃ­sticas"]["clean"].copy()

    inv["SKU_ID"] = inv["SKU_ID"].astype(str).str.strip()
    trx["SKU_ID"] = trx["SKU_ID"].astype(str).str.strip()

    merged = trx.merge(
        inv[["SKU_ID"]],
        on="SKU_ID",
        how="left",
        indicator=True
    )

    merged["sku_status"] = merged["_merge"].map({
        "both": "VALIDO",
        "left_only": "FANTASMA"
    })

    # NormalizaciÃ³n financiera
    merged["Cantidad_Vendida"] = merged["Cantidad_Vendida"].fillna(0)
    merged["Precio_Venta_Final"] = merged["Precio_Venta_Final"].fillna(0)
    merged["ingreso"] = merged["Cantidad_Vendida"] * merged["Precio_Venta_Final"]

    # ============================================================
    # DASHBOARD 1 â€“ VISIBILIDAD SKU FANTASMA
    # ============================================================
    st.subheader("ðŸ“¦ Visibilidad de SKUs Fantasma")

    resumen = merged["sku_status"].value_counts().reset_index()
    resumen.columns = ["Estado SKU", "Cantidad"]

    col1, col2, col3 = st.columns(3)
    col1.metric("Transacciones Totales", len(merged))
    col2.metric(
        "SKUs Fantasma",
        int(resumen.loc[resumen["Estado SKU"] == "FANTASMA", "Cantidad"].sum())
    )
    col3.metric(
        "% Transacciones Fantasma",
        f"{(resumen.loc[resumen['Estado SKU']=='FANTASMA','Cantidad'].sum() / len(merged))*100:.2f}%"
    )

    fig1, ax1 = plt.subplots(figsize=(6, 4))
    ax1.bar(
        resumen["Estado SKU"],
        resumen["Cantidad"],
        color=["#2ecc71", "#e74c3c"]
    )
    ax1.set_title("DistribuciÃ³n de Transacciones por Estado SKU")
    ax1.set_ylabel("NÃºmero de Transacciones")
    ax1.grid(axis="y", alpha=0.3)

    st.pyplot(fig1)

    # DESCARGA DEL GRÃFICO
    buf1 = io.BytesIO()
    fig1.savefig(buf1, format="png", bbox_inches="tight")
    buf1.seek(0)

    st.download_button(
        "ðŸ“¥ Descargar grÃ¡fico SKU (PNG)",
        buf1,
        "distribucion_sku_fantasma.png",
        "image/png"
    )

    st.download_button(
        "ðŸ“¥ Descargar resumen SKU (CSV)",
        resumen.to_csv(index=False),
        "resumen_sku_fantasma.csv",
        "text/csv"
    )

    # ============================================================
    # DASHBOARD 2 â€“ IMPACTO FINANCIERO
    # ============================================================
    st.subheader("ðŸ’° Impacto Financiero del SKU Fantasma")

    impacto = merged.groupby("sku_status")["ingreso"].sum().reset_index()

    total_ingresos = impacto["ingreso"].sum()
    ingresos_fantasma = impacto.loc[
        impacto["sku_status"] == "FANTASMA", "ingreso"
    ].sum()

    col1, col2 = st.columns(2)
    col1.metric("Ingreso Total (USD)", f"{total_ingresos:,.0f}")
    col2.metric(
        "% Ingresos en Riesgo",
        f"{(ingresos_fantasma / total_ingresos) * 100:.2f}%" if total_ingresos > 0 else "0%"
    )

    fig2, ax2 = plt.subplots(figsize=(6, 4))
    ax2.bar(
        impacto["sku_status"],
        impacto["ingreso"],
        color=["#2ecc71", "#e74c3c"]
    )
    ax2.set_title("Ingresos por Estado del SKU")
    ax2.set_ylabel("Ingreso (USD)")
    ax2.grid(axis="y", alpha=0.3)

    st.pyplot(fig2)

    buf2 = io.BytesIO()
    fig2.savefig(buf2, format="png", bbox_inches="tight")
    buf2.seek(0)

    st.download_button(
        "ðŸ“¥ Descargar impacto financiero (PNG)",
        buf2,
        "impacto_financiero_sku_fantasma.png",
        "image/png"
    )

    st.download_button(
        "ðŸ“¥ Descargar impacto financiero (CSV)",
        impacto.to_csv(index=False),
        "impacto_financiero_sku_fantasma.csv",
        "text/csv"
    )

    # ============================================================
    # DASHBOARD 3 â€“ STORYTELLING EJECUTIVO
    # ============================================================
    st.subheader("ðŸ§  Storytelling Ejecutivo del Riesgo Operativo")

    resumen_exec = merged.groupby("sku_status").agg(
        transacciones=("SKU_ID", "count"),
        ingreso_total=("ingreso", "sum"),
        ingreso_promedio=("ingreso", "mean")
    ).reset_index()

    st.dataframe(resumen_exec, use_container_width=True)

    st.download_button(
        "ðŸ“¥ Descargar resumen ejecutivo (CSV)",
        resumen_exec.to_csv(index=False),
        "resumen_ejecutivo_sku_fantasma.csv",
        "text/csv"
    )

    st.info(
        """
        ðŸ”Ž **Insight Ejecutivo**

        Los **SKUs Fantasma** representan transacciones sin respaldo en inventario fÃ­sico.

        âš ï¸ Impactos clave:
        - DistorsiÃ³n de KPIs financieros
        - SobreestimaciÃ³n de ingresos
        - Riesgo en auditorÃ­a y control interno

        âœ… **RecomendaciÃ³n**:
        Implementar validaciÃ³n obligatoria de SKU contra inventario maestro
        antes de permitir la transacciÃ³n.
        """
    )

# =============================================================================
# ========================= FASE 2.1 â€“ Variables Derivadas =====================
# =============================================================================

# Usaremos merged entre Transacciones + Inventario
# merged = trx.merge(inv, on="SKU_ID", how="left", indicator=True)

# ---------------------------
# 1. NormalizaciÃ³n defensiva
# ---------------------------

# Asegurarnos que las columnas crÃ­ticas existen
cols_necesarias = [
    "Cantidad_Vendida",
    "Precio_Venta_Final",
    "Costo_Envio",
    "Tiempo_Entrega_Real",
    "Lead_Time_Dias",
    "Ticket_Soporte_Abierto",
    "sku_status"
]

for col in cols_necesarias:
    if col not in merged.columns:
        merged[col] = 0

# Normalizamos tipos
merged["Cantidad_Vendida"] = merged["Cantidad_Vendida"].fillna(0)
merged["Precio_Venta_Final"] = merged["Precio_Venta_Final"].fillna(0)
merged["Costo_Envio"] = merged["Costo_Envio"].fillna(0)
merged["Tiempo_Entrega_Real"] = merged["Tiempo_Entrega_Real"].fillna(0)
merged["Lead_Time_Dias"] = merged["Lead_Time_Dias"].fillna(0)
merged["Ticket_Soporte_Abierto"] = merged["Ticket_Soporte_Abierto"].fillna(0).astype(int)
merged["sku_status"] = merged.get("sku_status", "VALIDO")

# ---------------------------
# 2. MÃ©tricas Financieras
# ---------------------------

merged["Ingreso"] = merged["Cantidad_Vendida"] * merged["Precio_Venta_Final"]
merged["Costo_Total"] = (merged["Cantidad_Vendida"] * merged["Costo_Unitario_USD"]) + merged["Costo_Envio"]
merged["Margen_Utilidad"] = merged["Ingreso"] - merged["Costo_Total"]
merged["Margen_Pct"] = merged.apply(lambda x: x["Margen_Utilidad"] / x["Ingreso"] if x["Ingreso"] > 0 else 0, axis=1)

# ---------------------------
# 3. MÃ©tricas LogÃ­sticas
# ---------------------------

merged["Brecha_Entrega_Dias"] = merged["Tiempo_Entrega_Real"] - merged["Lead_Time_Dias"]

# ---------------------------
# 4. MÃ©tricas de Soporte
# ---------------------------

ratio_soporte_categoria = (
    merged.groupby("Categoria", dropna=False)
    .agg(
        tickets_soporte=("Ticket_Soporte_Abierto", "sum"),
        transacciones=("Transaccion_ID", "count")
    )
    .reset_index()
)
ratio_soporte_categoria["Ratio_Soporte"] = ratio_soporte_categoria["tickets_soporte"] / ratio_soporte_categoria["transacciones"]

# ---------------------------
# 5. Riesgo Operativo
# ---------------------------

merged["Riesgo_Operativo"] = (
    (merged["sku_status"] == "FANTASMA") |
    (merged["Margen_Utilidad"] < 0) |
    (merged["Brecha_Entrega_Dias"] > 2) |
    (merged["Ticket_Soporte_Abierto"] == 1)
).astype(int)

# ---------------------------
# 6. Health Score (0â€“100)
# ---------------------------

merged["Health_Score"] = 100
merged.loc[merged["sku_status"] == "FANTASMA", "Health_Score"] -= 40
merged.loc[merged["Margen_Utilidad"] < 0, "Health_Score"] -= 30
merged.loc[merged["Brecha_Entrega_Dias"] > 2, "Health_Score"] -= 20
merged.loc[merged["Ticket_Soporte_Abierto"] == 1, "Health_Score"] -= 10
merged["Health_Score"] = merged["Health_Score"].clip(0, 100)




